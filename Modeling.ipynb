{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in y datasets\n",
    "yTrain = pd.read_csv('yTrain.csv').head(100000)\n",
    "yTest = pd.read_csv('yTest.csv').head(100000)\n",
    "\n",
    "# Target names for models\n",
    "target_names = ['Neutral', 'Depression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes\n",
    "def MNB(xTrain, xTest, yTrain, yTest, dataset, target_names):\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(xTrain, yTrain)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_mnb = mnb.predict(xTest)\n",
    "    y_pred_prob_mnb = mnb.predict_proba(xTest)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"MultinomialNB on {dataset} dataset:\")\n",
    "    print(classification_report(yTest, y_pred_mnb, target_names=target_names))\n",
    "\n",
    "    # Calculate precision, recall, and thresholds for AUPRC\n",
    "    precision, recall, _ = precision_recall_curve(yTest, y_pred_prob_mnb)\n",
    "\n",
    "    # Calculate AUPRC\n",
    "    auprc = auc(recall, precision)\n",
    "    print(f\"AUPRC (Area Under Precision-Recall Curve): {auprc:.4f}\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "def BNB(xTrain, xTest, yTrain, yTest, dataset, target_names):\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(xTrain, yTrain)\n",
    "    y_pred_bnb = bnb.predict(xTest)\n",
    "\n",
    "    y_pred_prob_bnb = bnb.predict_proba(xTest)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"BernoulliNB on {dataset} dataset:\")\n",
    "    print(classification_report(yTest, y_pred_bnb, target_names=target_names))\n",
    "\n",
    "    # Calculate precision, recall, and thresholds for AUPRC\n",
    "    precision, recall, _ = precision_recall_curve(yTest, y_pred_prob_bnb)\n",
    "\n",
    "    # Calculate AUPRC\n",
    "    auprc = auc(recall, precision)\n",
    "    print(f\"AUPRC (Area Under Precision-Recall Curve): {auprc:.4f}\")\n",
    "\n",
    "# KNN\n",
    "def KNN(xTrain, xTest, yTrain, yTest, dataset, target_names, k, metric):\n",
    "    knn = KNeighborsClassifier(metric=metric, n_neighbors=k)\n",
    "    knn.fit(xTrain.to_numpy(), yTrain)\n",
    "    y_pred_knn = knn.predict(xTest.to_numpy())\n",
    "    y_pred_prob_knn = knn.predict_proba(xTest)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"KNN on {dataset} dataset:\")\n",
    "    print(classification_report(yTest, y_pred_knn, target_names=target_names))\n",
    "\n",
    "    # Calculate precision, recall, and thresholds for AUPRC\n",
    "    precision, recall, _ = precision_recall_curve(yTest, y_pred_prob_knn)\n",
    "\n",
    "    # Calculate AUPRC\n",
    "    auprc = auc(recall, precision)\n",
    "    print(f\"AUPRC (Area Under Precision-Recall Curve): {auprc:.4f}\")\n",
    "\n",
    "# Perceptron\n",
    "def PERC(xTrain, xTest, yTrain, yTest, dataset, target_names, eta0, max_iter, penalty, tol):\n",
    "    perc = Perceptron(eta0=eta0, max_iter=max_iter, penalty=penalty, tol=tol, random_state=42)\n",
    "    perc.fit(xTrain, yTrain)\n",
    "    y_pred_perc = perc.predict(xTest)\n",
    "    print(f\"Perceptron on {dataset} dataset:\")\n",
    "    print(classification_report(yTest, y_pred_perc, target_names=target_names))\n",
    "\n",
    "# Logistic Regression\n",
    "def LR(xTrain, xTest, yTrain, yTest, dataset, target_names, penalty, tol, solver, max_iters):\n",
    "    lr = LogisticRegression(max_iter=max_iters, penalty=penalty, tol=tol, solver=solver, random_state=42)\n",
    "    lr.fit(xTrain, yTrain)\n",
    "    y_pred_lr = lr.predict(xTest)\n",
    "    y_pred_prob_lr = lr.predict_proba(xTest)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"Logistic Regression on {dataset} dataset:\")\n",
    "    print(classification_report(yTest, y_pred_lr, target_names=target_names))\n",
    "\n",
    "    # Calculate precision, recall, and thresholds for AUPRC\n",
    "    precision, recall, _ = precision_recall_curve(yTest, y_pred_prob_lr)\n",
    "\n",
    "    # Calculate AUPRC\n",
    "    auprc = auc(recall, precision)\n",
    "    print(f\"AUPRC (Area Under Precision-Recall Curve): {auprc:.4f}\")\n",
    "\n",
    "# Decision Tree\n",
    "def DT(xTrain, xTest, yTrain, yTest, dataset, target_names, min_sample_split, min_samples_leaf, max_depth):\n",
    "    dt = DecisionTreeClassifier(random_state=42, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_samples_split=min_sample_split)\n",
    "    dt.fit(xTrain, yTrain)\n",
    "    y_pred_dt = dt.predict(xTest)\n",
    "    y_pred_prob_dt = dt.predict_proba(xTest)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"Decision Tree on {dataset} dataset:\")\n",
    "    print(classification_report(yTest, y_pred_dt, target_names=target_names))\n",
    "\n",
    "    # Calculate precision, recall, and thresholds for AUPRC\n",
    "    precision, recall, _ = precision_recall_curve(yTest, y_pred_prob_dt)\n",
    "\n",
    "    # Calculate AUPRC\n",
    "    auprc = auc(recall, precision)\n",
    "    print(f\"AUPRC (Area Under Precision-Recall Curve): {auprc:.4f}\")\n",
    "\n",
    "# Random Forest\n",
    "def RF(xTrain, xTest, yTrain, yTest, dataset, target_names, max_depth, max_feature, min_samples_leaf, n_estimators):\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=max_feature, min_samples_leaf=min_samples_leaf, random_state=42)\n",
    "    rf.fit(xTrain, yTrain)\n",
    "    y_pred_rf = rf.predict(xTest)\n",
    "    y_pred_prob_rf = rf.predict_proba(xTest)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"Random Forest on {dataset} dataset:\")\n",
    "    print(classification_report(yTest, y_pred_rf, target_names=target_names))\n",
    "\n",
    "    # Calculate precision, recall, and thresholds for AUPRC\n",
    "    precision, recall, _ = precision_recall_curve(yTest, y_pred_prob_rf)\n",
    "\n",
    "    # Calculate AUPRC\n",
    "    auprc = auc(recall, precision)\n",
    "    print(f\"AUPRC (Area Under Precision-Recall Curve): {auprc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Dataset\n",
    "binary_df_train = pd.read_csv('binary_df_train.csv').head(100000)\n",
    "binary_df_test = pd.read_csv('binary_df_test.csv').head(100000)\n",
    "\n",
    "MNB(binary_df_train, binary_df_test, yTrain, yTest, 'binary', target_names)\n",
    "BNB(binary_df_train, binary_df_test, yTrain, yTest, 'binary', target_names)\n",
    "PERC(binary_df_train, binary_df_test, yTrain, yTest, 'binary', target_names, 0.01, 10, None, 0.01)\n",
    "LR(binary_df_train, binary_df_test, yTrain, yTest, 'binary', target_names, None, 0.001, 'sag', 30)\n",
    "DT(binary_df_train, binary_df_test, yTrain, yTest, 'binary', target_names, 50, 30, 20)\n",
    "RF(binary_df_train, binary_df_test, yTrain, yTest, 'binary', target_names, None, 'sqrt', 4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words Dataset\n",
    "bow_df_train = pd.read_csv('bow_df_train.csv').head(100000)\n",
    "bow_df_test = pd.read_csv('bow_df_test.csv').head(100000)\n",
    "\n",
    "MNB(bow_df_train, bow_df_test, yTrain, yTest, 'bow', target_names)\n",
    "BNB(bow_df_train, bow_df_test, yTrain, yTest, 'bow', target_names)\n",
    "PERC(bow_df_train, bow_df_test, yTrain, yTest, 'bow', target_names, 1, 10, None, 0.001)\n",
    "LR(bow_df_train, bow_df_test, yTrain, yTest, 'bow', target_names, 'l2', 0.001, 'liblinear', 10)\n",
    "DT(bow_df_train, bow_df_test, yTrain, yTest, 'bow', target_names, 30, 20, 20)\n",
    "RF(bow_df_train, bow_df_test, yTrain, yTest, 'bow', target_names, None, 'log2', 2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tfidf Dataset\n",
    "tfidf_df_train = pd.read_csv('tfidf_df_train.csv').head(100000)\n",
    "tfidf_df_test = pd.read_csv('tfidf_df_test.csv').head(100000)\n",
    "\n",
    "MNB(tfidf_df_train, tfidf_df_test, yTrain, yTest, 'tfidf', target_names)\n",
    "BNB(tfidf_df_train, tfidf_df_test, yTrain, yTest, 'tfidf', target_names)\n",
    "PERC(tfidf_df_train, tfidf_df_test, yTrain, yTest, 'tfidf', target_names, 0.00001, 10, None, 0.01)\n",
    "LR(tfidf_df_train, tfidf_df_test, yTrain, yTest, 'tfidf', target_names, None, 1e-06, 'sag', 10)\n",
    "DT(tfidf_df_train, tfidf_df_test, yTrain, yTest, 'tfidf', target_names, 50, 20, 20)\n",
    "RF(tfidf_df_train, tfidf_df_test, yTrain, yTest, 'tfidf', target_names, None, 'sqrt', 4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash Dataset\n",
    "hash_df_train = pd.read_csv('hash_df_train.csv').head(100000)\n",
    "hash_df_test = pd.read_csv('hash_df_test.csv').head(100000)\n",
    "\n",
    "BNB(hash_df_train, hash_df_test, yTrain, yTest, 'hashing', target_names)\n",
    "PERC(hash_df_train, hash_df_test, yTrain, yTest, 'hashing', target_names, 0.01, 20, 'l2', 0.000001)\n",
    "LR(hash_df_train, hash_df_test, yTrain, yTest, 'hashing', target_names, None, 0.001, 'saga', 10)\n",
    "DT(hash_df_train, hash_df_test, yTrain, yTest, 'hashing', target_names, 30, 10, 20)\n",
    "RF(hash_df_train, hash_df_test, yTrain, yTest, 'hashing', target_names, None, 'sqrt', 4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA Dataset\n",
    "lda_df_train = pd.read_csv('lda_df_train.csv').head(100000)\n",
    "lda_df_test = pd.read_csv('lda_df_test.csv').head(100000)\n",
    "\n",
    "MNB(lda_df_train, lda_df_test, yTrain, yTest, 'LDA', target_names)\n",
    "BNB(lda_df_train, lda_df_test, yTrain, yTest, 'LDA', target_names)\n",
    "KNN(lda_df_train, lda_df_test, yTrain, yTest, 'LDA', target_names, 7, 'manhattan')\n",
    "PERC(lda_df_train, lda_df_test, yTrain, yTest, 'LDA', target_names, 0.01, 10, 'l2', 0.01)\n",
    "LR(lda_df_train, lda_df_test, yTrain, yTest, 'LDA', target_names, None, 1e-05, 'sag', 10)\n",
    "DT(lda_df_train, lda_df_test, yTrain, yTest, 'LDA', target_names, 50, 10, 10)\n",
    "RF(lda_df_train, lda_df_test, yTrain, yTest, 'LDA', target_names, 5, None, 4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Dataset\n",
    "pca_df_train = pd.read_csv('pca_df_train.csv').head(100000)\n",
    "pca_df_test = pd.read_csv('pca_df_test.csv').head(100000)\n",
    "\n",
    "BNB(pca_df_train, pca_df_test, yTrain, yTest, 'PCA', target_names)\n",
    "KNN(pca_df_train, pca_df_test, yTrain, yTest, 'PCA', target_names, 13, 'euclidean')\n",
    "PERC(pca_df_train, pca_df_test, yTrain, yTest, 'PCA', target_names, 1, 10, 'elasticnet', 0.01)\n",
    "LR(pca_df_train, pca_df_test, yTrain, yTest, 'PCA', target_names, None, 1e-06, 'sag', 10)\n",
    "DT(pca_df_train, pca_df_test, yTrain, yTest, 'PCA', target_names, 10, 30, 20)\n",
    "RF(pca_df_train, pca_df_test, yTrain, yTest, 'PCA', target_names, None, 'sqrt', 1, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS334",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
