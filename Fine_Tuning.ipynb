{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in files and train test split\n",
    "x = pd.read_csv('x.csv')\n",
    "y = pd.read_csv('y.csv')\n",
    "xTrain,xTest,yTrain,yTest = train_test_split(x, y, train_size=0.7, shuffle=True)\n",
    "xTrain.to_csv('xTrain.csv', index=False)\n",
    "xTest.to_csv('xTest.csv', index=False)\n",
    "yTrain.to_csv('yTrain.csv', index=False)\n",
    "yTest.to_csv('yTest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tranform data using bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "xTrain = pd.read_csv('xTrain.csv')\n",
    "xTest = pd.read_csv('xTest.csv')\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=500)\n",
    "vectorizer.fit(xTrain['cleaned_content'])\n",
    "bow_df_train = vectorizer.transform(xTrain['cleaned_content'])\n",
    "bow_df_test = vectorizer.transform(xTest['cleaned_content'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "bow_df_train = pd.DataFrame(bow_df_train.toarray(), columns=feature_names)\n",
    "bow_df_test = pd.DataFrame(bow_df_test.toarray(), columns=feature_names)\n",
    "bow_df_train.to_csv('bow_df_train.csv', index=False)\n",
    "bow_df_test.to_csv('bow_df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tranform data using binary\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "xTrain = pd.read_csv('xTrain.csv')\n",
    "xTest = pd.read_csv('xTest.csv')\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=500, binary=True)\n",
    "vectorizer.fit(xTrain['cleaned_content'])\n",
    "binary_df_train = vectorizer.transform(xTrain['cleaned_content'])\n",
    "binary_df_test = vectorizer.transform(xTest['cleaned_content'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "binary_df_train = pd.DataFrame(binary_df_train.toarray(), columns=feature_names)\n",
    "binary_df_test = pd.DataFrame(binary_df_test.toarray(), columns=feature_names)\n",
    "binary_df_train.to_csv('binary_df_train.csv', index=False)\n",
    "binary_df_test.to_csv('binary_df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data using tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "xTrain = pd.read_csv('xTrain.csv')\n",
    "xTest = pd.read_csv('xTest.csv')\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "vectorizer.fit(xTrain['cleaned_content'])\n",
    "tfidf_df_train = vectorizer.transform(xTrain['cleaned_content'])\n",
    "tfidf_df_test = vectorizer.transform(xTest['cleaned_content'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_df_train = pd.DataFrame(tfidf_df_train.toarray(), columns=feature_names)\n",
    "tfidf_df_test = pd.DataFrame(tfidf_df_test.toarray(), columns=feature_names)\n",
    "tfidf_df_train.to_csv('tfidf_df_train.csv', index=False)\n",
    "tfidf_df_test.to_csv('tfidf_df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data using hashing vectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "xTrain = pd.read_csv('xTrain.csv')\n",
    "xTest = pd.read_csv('xTest.csv')\n",
    "\n",
    "vectorizer = HashingVectorizer(n_features=500)\n",
    "vectorizer.fit(xTrain['cleaned_content'])\n",
    "hash_df_train = vectorizer.transform(xTrain['cleaned_content'])\n",
    "hash_df_test = vectorizer.transform(xTest['cleaned_content'])\n",
    "hash_df_train = pd.DataFrame(hash_df_train.toarray())\n",
    "hash_df_test = pd.DataFrame(hash_df_test.toarray())\n",
    "hash_df_train.to_csv('hash_df_train.csv', index=False)\n",
    "hash_df_test.to_csv('hash_df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data using non-negative matrix factorization (NMF)\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "tfidf_df_train = pd.read_csv('tfidf_df_train.csv')\n",
    "tfidf_df_test = pd.read_csv('tfidf_df_test.csv')\n",
    "\n",
    "nmf = NMF(n_components=10, random_state=100)\n",
    "nmf.fit(tfidf_df_train)\n",
    "nmf_df_train = nmf.transform(tfidf_df_train)\n",
    "nmf_df_test = nmf.transform(tfidf_df_test)\n",
    "nmf_df_train = pd.DataFrame(nmf_df_train)\n",
    "nmf_df_test = pd.DataFrame(nmf_df_test)\n",
    "nmf_df_train.to_csv('nmf_df_train.csv', index=False)\n",
    "nmf_df_test.to_csv('nmf_df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting topic/features using LDA\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Assuming that 'tfidf_df_train.csv' and 'tfidf_df_test.csv' contain the TF-IDF vectors\n",
    "tfidf_df_train = pd.read_csv('tfidf_df_train.csv')\n",
    "tfidf_df_test = pd.read_csv('tfidf_df_test.csv')\n",
    "\n",
    "# Applying LDA\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "\n",
    "# Fit LDA on the training data\n",
    "X_lda_train = lda.fit_transform(tfidf_df_train)\n",
    "\n",
    "# Transform the test data using the fitted LDA\n",
    "X_lda_test = lda.transform(tfidf_df_test)\n",
    "\n",
    "# Convert the LDA-transformed data to DataFrames for saving into CSV files\n",
    "lda_df_train = pd.DataFrame(X_lda_train)\n",
    "lda_df_test = pd.DataFrame(X_lda_test)\n",
    "\n",
    "# Save the LDA features to CSV files\n",
    "lda_df_train.to_csv('lda_df_train.csv', index=False)\n",
    "lda_df_test.to_csv('lda_df_test.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Read the already transformed TF-IDF data\n",
    "tfidf_df_train = pd.read_csv('tfidf_df_train.csv')\n",
    "tfidf_df_test = pd.read_csv('tfidf_df_test.csv')\n",
    "\n",
    "# Initialize PCA, choose the number of components you want, for example, 10\n",
    "pca = PCA(n_components=10, random_state=42)\n",
    "\n",
    "# Fit PCA on the training data and transform it\n",
    "pca_df_train = pca.fit_transform(tfidf_df_train)\n",
    "\n",
    "# Transform the test data using the already fitted PCA\n",
    "pca_df_test = pca.transform(tfidf_df_test)\n",
    "\n",
    "# Convert the PCA results to DataFrame to save them into CSV files\n",
    "pca_df_train = pd.DataFrame(pca_df_train)\n",
    "pca_df_test = pd.DataFrame(pca_df_test)\n",
    "\n",
    "# Save the PCA features into CSV files\n",
    "pca_df_train.to_csv('pca_df_train.csv', index=False)\n",
    "pca_df_test.to_csv('pca_df_test.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS334",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
